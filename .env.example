GOOGLE_CLOUD_PROJECT_ID="your-project-id"

# Configuration pour l'usage direct en terminal (main.py uniquement)
# Le serveur MCP n'a PAS besoin de ces clés - il utilise le LLM du client

# Choisissez votre provider LLM pour l'usage direct
# Options supportées: gemini, claude, openai, ollama
LLM_PROVIDER="gemini"

# Configuration Gemini (si LLM_PROVIDER=gemini)
GEMINI_API_KEY="your-gemini-api-key"

# Configuration Claude (si LLM_PROVIDER=claude)
ANTHROPIC_API_KEY="your-claude-api-key"

# Configuration OpenAI (si LLM_PROVIDER=openai)
OPENAI_API_KEY="your-openai-api-key"

# Configuration Ollama (si LLM_PROVIDER=ollama)
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL="llama2"

